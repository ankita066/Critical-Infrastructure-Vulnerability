{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Download wind, precipitation and snowfall data from NASA GISC </h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from os import listdir\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from pydap.client import open_url\n",
    "from pydap.cas.urs import setup_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change user_name and pw to access NASA server\n",
    "#Wind data can be changed to daily dataset\n",
    "\n",
    "#wind data - https://disc.gsfc.nasa.gov/datasets/M2TUNXFLX_5.12.4/summary?keywords=M2TUNXFLX\n",
    "#power station data - https://hifld-geoplatform.opendata.arcgis.com/datasets/geoplatform::power-plants-2/explore?location=33.045427%2C65.943052%2C3.00&showTable=true\n",
    "\n",
    "nasa_url = \"https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/\"\n",
    "user_name = \"XXX\"\n",
    "pw = \"xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_dir = \"/Users/bhaumik/Spring 2022/Xinformatics/Power_Station_Vulnerability_Due_to_Wind/Surface Flux analysis/\"\n",
    "\n",
    "\n",
    "with open(project_dir + 'surface_flux_monthly.txt') as f:\n",
    "    wind_files = f.read().splitlines()\n",
    "wind_files[1][45:]\n",
    "\n",
    "len(wind_files)\n",
    "# wind_files[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Merge with power station locations from HIFLD</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open power station file (downloaded from link above), get latitude/longitude of each power station\n",
    "station_filename = project_dir + \"Power_Plants.csv\" #download from above link\n",
    "station_data = pd.read_csv(station_filename)\n",
    "station_lats=station_data[\"LATITUDE\"]\n",
    "station_lons=station_data[\"LONGITUDE\"]\n",
    "\n",
    "#for each power station location, find the index of the correct latitude/longitude grid in the wind files\n",
    "lat_idx = np.zeros((len(station_lats),1),dtype='int') #preallocate\n",
    "lon_idx = np.zeros((len(station_lons),1),dtype='int') #preallocate\n",
    "for i in range(len(station_lats)):\n",
    "    lat_idx[i] = round((station_lats[i] - -90)/0.5)\n",
    "    lon_idx[i] = round((station_lons[i] - -180)/0.625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preallocate storage arrays\n",
    "#station_mean = np.zeros((len(station_lats),len(wind_files)))\n",
    "station_max_prec = np.zeros((len(station_lats),len(wind_files)))\n",
    "station_max_ws = np.zeros((len(station_lats),len(wind_files)))\n",
    "station_max_prec_tot = np.zeros((len(station_lats),len(wind_files)))\n",
    "station_max_snow = np.zeros((len(station_lats),len(wind_files)))\n",
    "years = np.zeros((1,len(wind_files)),dtype='int')\n",
    "months = np.zeros((1,len(wind_files)),dtype='int')\n",
    "days = np.zeros((1,len(wind_files)),dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1 of 13\n",
      "Processing file 2 of 13\n",
      "Processing file 3 of 13\n",
      "Processing file 4 of 13\n",
      "Processing file 5 of 13\n",
      "Processing file 6 of 13\n",
      "Processing file 7 of 13\n",
      "Processing file 8 of 13\n",
      "Processing file 9 of 13\n",
      "Processing file 10 of 13\n",
      "Processing file 11 of 13\n",
      "Processing file 12 of 13\n"
     ]
    }
   ],
   "source": [
    "session_url = nasa_url + wind_files[1][45:]\n",
    "# print(session_url)\n",
    "session = setup_session(user_name, pw, check_url=session_url)\n",
    "\n",
    "for i in range(1,len(wind_files)):\n",
    "    \n",
    "    print(\"Processing file \" + str(i) + \" of \" + str(len(wind_files)))\n",
    "    dataset_url = nasa_url + wind_files[i][45:]\n",
    "    # print(dataset_url)\n",
    "    dataset = open_url(dataset_url, session=session)\n",
    "    \n",
    "    prec = dataset.PRECTOT\n",
    "    speed_max = dataset.SPEEDMAX\n",
    "    snow = dataset.PRECSNO\n",
    "    prectot = dataset.PRECTOTCORR\n",
    "\n",
    "\n",
    "    prec_nans = prec[:].data\n",
    "    _FillValueprec = dataset.PRECTOT.attributes['_FillValue']\n",
    "    prec_nans[prec_nans == _FillValueprec] = np.nan\n",
    "    prec_daily_max = prec_nans.max(axis=0) #calculate daily max wind speed from hourly data\n",
    "    # print(prec_daily_max)\n",
    "\n",
    "    speed_max_nans = speed_max[:].data\n",
    "    _FillValueprec = dataset.SPEEDMAX.attributes['_FillValue']\n",
    "    speed_max_nans[speed_max_nans == _FillValueprec] = np.nan\n",
    "    speed_max_nans_daily = speed_max_nans.max(axis=0) #calculate daily max wind speed from hourly data\n",
    "\n",
    "    snow_nans = snow[:].data\n",
    "    _FillValueprec = dataset.PRECSNO.attributes['_FillValue']\n",
    "    snow_nans[snow_nans == _FillValueprec] = np.nan\n",
    "    snow_daily_max = snow_nans.max(axis=0) #calculate daily max wind speed from hourly data\n",
    "\n",
    "    prectot_nans = prectot[:].data\n",
    "    _FillValueprec = dataset.PRECTOTCORR.attributes['_FillValue']\n",
    "    prectot_nans[prectot_nans == _FillValueprec] = np.nan\n",
    "    prectot_daily_max = prectot_nans.max(axis=0) #calculate daily max wind speed from hourly data\n",
    "\n",
    "    for j in range(len(station_lats)):      \n",
    "        station_max_prec[j][i] = prec_daily_max[lat_idx[j][0]][lon_idx[j][0]]  #get max wind data for each station\n",
    "        station_max_ws[j][i] = speed_max_nans_daily[lat_idx[j][0]][lon_idx[j][0]]\n",
    "        station_max_prec_tot[j][i] = snow_daily_max[lat_idx[j][0]][lon_idx[j][0]]\n",
    "        station_max_snow[j][i] = prectot_daily_max[lat_idx[j][0]][lon_idx[j][0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Convert netCDF data to .csv</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude/longitude of each power station\n",
    "station_locations = np.transpose(np.vstack((station_lats.to_numpy(), station_lons.to_numpy())))\n",
    "with open(project_dir + 'station_locations_southeast.csv', 'w', newline='') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(station_locations)\n",
    "\n",
    "#daily max wind of each power station\n",
    "with open(project_dir + 'station_max_ws.csv', 'w', newline='') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(station_max_ws)\n",
    "\n",
    "#daily max precipitation of each power station\n",
    "with open(project_dir + 'station_max_prec_southeast.csv', 'w', newline='') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(station_max_prec)\n",
    "\n",
    "#daily total precipiatation of each power station\n",
    "with open(project_dir + 'station_max_prec_tot_southeast.csv', 'w', newline='') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(station_max_prec_tot)\n",
    "\n",
    "#daily snowfall of each power station\n",
    "with open(project_dir + 'station_max_snow_southeast.csv', 'w', newline='') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(station_max_snow)\n",
    "\n",
    "#date of wind measurement, column headers for mean wind and max wind files\n",
    "dates = np.vstack((years, months, days))\n",
    "with open(project_dir + 'dates_southeast.csv', 'w', newline='') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(dates)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e03034aa8adaa808f8f1df457388ce77add18ad0196c361115e9c7fe7b08b9b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
